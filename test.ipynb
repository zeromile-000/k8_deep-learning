{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Downloading torch-2.5.1-cp312-cp312-win_amd64.whl.metadata (28 kB)\n",
      "Collecting filelock (from torch)\n",
      "  Using cached filelock-3.16.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting typing-extensions>=4.8.0 (from torch)\n",
      "  Using cached typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting networkx (from torch)\n",
      "  Using cached networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting jinja2 (from torch)\n",
      "  Using cached jinja2-3.1.4-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting fsspec (from torch)\n",
      "  Using cached fsspec-2024.10.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: setuptools in c:\\users\\user\\anaconda3\\envs\\torch_book\\lib\\site-packages (from torch) (75.1.0)\n",
      "Collecting sympy==1.13.1 (from torch)\n",
      "  Using cached sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy==1.13.1->torch)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->torch)\n",
      "  Downloading MarkupSafe-3.0.2-cp312-cp312-win_amd64.whl.metadata (4.1 kB)\n",
      "Downloading torch-2.5.1-cp312-cp312-win_amd64.whl (203.0 MB)\n",
      "   ---------------------------------------- 0.0/203.0 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 12.6/203.0 MB 60.7 MB/s eta 0:00:04\n",
      "   ------ --------------------------------- 31.2/203.0 MB 73.3 MB/s eta 0:00:03\n",
      "   -------- ------------------------------- 43.5/203.0 MB 71.0 MB/s eta 0:00:03\n",
      "   ----------- ---------------------------- 58.7/203.0 MB 70.6 MB/s eta 0:00:03\n",
      "   --------------- ------------------------ 76.5/203.0 MB 74.0 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 84.4/203.0 MB 69.1 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 97.0/203.0 MB 67.3 MB/s eta 0:00:02\n",
      "   --------------------- ----------------- 110.1/203.0 MB 67.0 MB/s eta 0:00:02\n",
      "   ----------------------- --------------- 124.0/203.0 MB 66.6 MB/s eta 0:00:02\n",
      "   -------------------------- ------------ 138.1/203.0 MB 66.9 MB/s eta 0:00:01\n",
      "   ----------------------------- --------- 152.3/203.0 MB 67.1 MB/s eta 0:00:01\n",
      "   -------------------------------- ------ 168.0/203.0 MB 67.5 MB/s eta 0:00:01\n",
      "   ----------------------------------- --- 183.2/203.0 MB 68.1 MB/s eta 0:00:01\n",
      "   --------------------------------------  199.5/203.0 MB 68.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  202.9/203.0 MB 69.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  202.9/203.0 MB 69.0 MB/s eta 0:00:01\n",
      "   --------------------------------------- 203.0/203.0 MB 57.7 MB/s eta 0:00:00\n",
      "Using cached sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "Using cached typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
      "Using cached filelock-3.16.1-py3-none-any.whl (16 kB)\n",
      "Using cached fsspec-2024.10.0-py3-none-any.whl (179 kB)\n",
      "Using cached jinja2-3.1.4-py3-none-any.whl (133 kB)\n",
      "Using cached networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
      "Downloading MarkupSafe-3.0.2-cp312-cp312-win_amd64.whl (15 kB)\n",
      "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Installing collected packages: mpmath, typing-extensions, sympy, networkx, MarkupSafe, fsspec, filelock, jinja2, torch\n",
      "Successfully installed MarkupSafe-3.0.2 filelock-3.16.1 fsspec-2024.10.0 jinja2-3.1.4 mpmath-1.3.0 networkx-3.4.2 sympy-1.13.1 torch-2.5.1 typing-extensions-4.12.2\n"
     ]
    }
   ],
   "source": [
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA 사용 가능 여부 : True\n",
      "현재 사용 device : cuda:0\n",
      "CUDA Index : 0\n",
      "GPU 이름 : NVIDIA GeForce RTX 2070\n",
      "GPU 개수 : 1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "USE_CUDA =torch.cuda.is_available()\n",
    "device =torch.device('cuda:0'if USE_CUDA else 'cpu')\n",
    "print('CUDA 사용 가능 여부 :', USE_CUDA)\n",
    "print('현재 사용 device :', device)\n",
    "print('CUDA Index :', torch.cuda.current_device())\n",
    "print('GPU 이름 :', torch.cuda.get_device_name())\n",
    "print('GPU 개수 :', torch.cuda.device_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numpy\n",
      "  Downloading numpy-2.2.0-cp312-cp312-win_amd64.whl.metadata (60 kB)\n",
      "Downloading numpy-2.2.0-cp312-cp312-win_amd64.whl (12.6 MB)\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   ---------------------------------------  12.6/12.6 MB 79.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.6/12.6 MB 60.8 MB/s eta 0:00:00\n",
      "Installing collected packages: numpy\n",
      "Successfully installed numpy-2.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch 버전: 2.5.1+cpu\n",
      "CUDA 사용 가능 여부: False\n",
      "CUDA 버전: None\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA 사용 가능 여부:\u001b[39m\u001b[38;5;124m\"\u001b[39m, torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available())\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA 버전:\u001b[39m\u001b[38;5;124m\"\u001b[39m, torch\u001b[38;5;241m.\u001b[39mversion\u001b[38;5;241m.\u001b[39mcuda)\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGPU 이름:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_device_name\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\cuda\\__init__.py:493\u001b[0m, in \u001b[0;36mget_device_name\u001b[1;34m(device)\u001b[0m\n\u001b[0;32m    481\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_device_name\u001b[39m(device: Optional[_device_t] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[0;32m    482\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Get the name of a device.\u001b[39;00m\n\u001b[0;32m    483\u001b[0m \n\u001b[0;32m    484\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    491\u001b[0m \u001b[38;5;124;03m        str: the name of the device\u001b[39;00m\n\u001b[0;32m    492\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 493\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mget_device_properties\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mname\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\cuda\\__init__.py:523\u001b[0m, in \u001b[0;36mget_device_properties\u001b[1;34m(device)\u001b[0m\n\u001b[0;32m    513\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_device_properties\u001b[39m(device: _device_t) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m _CudaDeviceProperties:\n\u001b[0;32m    514\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Get the properties of a device.\u001b[39;00m\n\u001b[0;32m    515\u001b[0m \n\u001b[0;32m    516\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    521\u001b[0m \u001b[38;5;124;03m        _CudaDeviceProperties: the properties of the device\u001b[39;00m\n\u001b[0;32m    522\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 523\u001b[0m     \u001b[43m_lazy_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# will define _get_device_properties\u001b[39;00m\n\u001b[0;32m    524\u001b[0m     device \u001b[38;5;241m=\u001b[39m _get_device_index(device, optional\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    525\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m device \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m device \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m device_count():\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\cuda\\__init__.py:310\u001b[0m, in \u001b[0;36m_lazy_init\u001b[1;34m()\u001b[0m\n\u001b[0;32m    305\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    306\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot re-initialize CUDA in forked subprocess. To use CUDA with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    307\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultiprocessing, you must use the \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspawn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m start method\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    308\u001b[0m     )\n\u001b[0;32m    309\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(torch\u001b[38;5;241m.\u001b[39m_C, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_cuda_getDeviceCount\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 310\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTorch not compiled with CUDA enabled\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    311\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _cudart \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    312\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[0;32m    313\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlibcudart functions unavailable. It looks like you have a broken build?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    314\u001b[0m     )\n",
      "\u001b[1;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"PyTorch 버전:\", torch.__version__)\n",
    "print(\"CUDA 사용 가능 여부:\", torch.cuda.is_available())\n",
    "print(\"CUDA 버전:\", torch.version.cuda)\n",
    "print(\"GPU 이름:\", torch.cuda.get_device_name(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channels:\n",
      " - pytorch\n",
      " - nvidia\n",
      " - defaults\n",
      " - conda-forge\n",
      "Platform: win-64\n",
      "Collecting package metadata (repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: c:\\Users\\user\\anaconda3\\envs\\py3_11\n",
      "\n",
      "  added / updated specs:\n",
      "    - pytorch-cuda=12.1\n",
      "    - pytorch==2.2.2\n",
      "    - torchaudio==2.2.2\n",
      "    - torchvision==0.17.2\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    certifi-2024.12.14         |  py312haa95532_0         162 KB\n",
      "    pillow-11.0.0              |  py312h096bfcc_1         901 KB\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:         1.0 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  blas               pkgs/main/win-64::blas-1.0-mkl \n",
      "  brotli-python      pkgs/main/win-64::brotli-python-1.0.9-py312hd77b12b_8 \n",
      "  certifi            pkgs/main/win-64::certifi-2024.12.14-py312haa95532_0 \n",
      "  charset-normalizer pkgs/main/noarch::charset-normalizer-3.3.2-pyhd3eb1b0_0 \n",
      "  cuda-cccl          nvidia/win-64::cuda-cccl-12.6.77-0 \n",
      "  cuda-cccl_win-64   nvidia/noarch::cuda-cccl_win-64-12.6.77-0 \n",
      "  cuda-cudart        nvidia/win-64::cuda-cudart-12.1.105-0 \n",
      "  cuda-cudart-dev    nvidia/win-64::cuda-cudart-dev-12.1.105-0 \n",
      "  cuda-cupti         nvidia/win-64::cuda-cupti-12.1.105-0 \n",
      "  cuda-libraries     nvidia/win-64::cuda-libraries-12.1.0-0 \n",
      "  cuda-libraries-dev nvidia/win-64::cuda-libraries-dev-12.1.0-0 \n",
      "  cuda-nvrtc         nvidia/win-64::cuda-nvrtc-12.1.105-0 \n",
      "  cuda-nvrtc-dev     nvidia/win-64::cuda-nvrtc-dev-12.1.105-0 \n",
      "  cuda-nvtx          nvidia/win-64::cuda-nvtx-12.1.105-0 \n",
      "  cuda-opencl        nvidia/win-64::cuda-opencl-12.6.77-0 \n",
      "  cuda-opencl-dev    nvidia/win-64::cuda-opencl-dev-12.6.77-0 \n",
      "  cuda-profiler-api  nvidia/win-64::cuda-profiler-api-12.6.77-0 \n",
      "  cuda-runtime       nvidia/win-64::cuda-runtime-12.1.0-0 \n",
      "  cuda-version       nvidia/noarch::cuda-version-12.6-3 \n",
      "  filelock           pkgs/main/win-64::filelock-3.13.1-py312haa95532_0 \n",
      "  freetype           pkgs/main/win-64::freetype-2.12.1-ha860e81_0 \n",
      "  idna               pkgs/main/win-64::idna-3.7-py312haa95532_0 \n",
      "  intel-openmp       pkgs/main/win-64::intel-openmp-2023.1.0-h59b6b97_46320 \n",
      "  jinja2             pkgs/main/win-64::jinja2-3.1.4-py312haa95532_1 \n",
      "  jpeg               pkgs/main/win-64::jpeg-9e-h827c3e9_3 \n",
      "  lcms2              pkgs/main/win-64::lcms2-2.16-hb4a4139_0 \n",
      "  lerc               pkgs/main/win-64::lerc-4.0.0-h5da7b33_0 \n",
      "  libcublas          nvidia/win-64::libcublas-12.1.0.26-0 \n",
      "  libcublas-dev      nvidia/win-64::libcublas-dev-12.1.0.26-0 \n",
      "  libcufft           nvidia/win-64::libcufft-11.0.2.4-0 \n",
      "  libcufft-dev       nvidia/win-64::libcufft-dev-11.0.2.4-0 \n",
      "  libcurand          nvidia/win-64::libcurand-10.3.7.77-0 \n",
      "  libcurand-dev      nvidia/win-64::libcurand-dev-10.3.7.77-0 \n",
      "  libcusolver        nvidia/win-64::libcusolver-11.4.4.55-0 \n",
      "  libcusolver-dev    nvidia/win-64::libcusolver-dev-11.4.4.55-0 \n",
      "  libcusparse        nvidia/win-64::libcusparse-12.0.2.55-0 \n",
      "  libcusparse-dev    nvidia/win-64::libcusparse-dev-12.0.2.55-0 \n",
      "  libdeflate         pkgs/main/win-64::libdeflate-1.22-h5bf469e_0 \n",
      "  libjpeg-turbo      pkgs/main/win-64::libjpeg-turbo-2.0.0-h196d8e1_0 \n",
      "  libnpp             nvidia/win-64::libnpp-12.0.2.50-0 \n",
      "  libnpp-dev         nvidia/win-64::libnpp-dev-12.0.2.50-0 \n",
      "  libnvjitlink       nvidia/win-64::libnvjitlink-12.1.105-0 \n",
      "  libnvjitlink-dev   nvidia/win-64::libnvjitlink-dev-12.1.105-0 \n",
      "  libnvjpeg          nvidia/win-64::libnvjpeg-12.1.1.14-0 \n",
      "  libnvjpeg-dev      nvidia/win-64::libnvjpeg-dev-12.1.1.14-0 \n",
      "  libpng             pkgs/main/win-64::libpng-1.6.39-h8cc25b3_0 \n",
      "  libtiff            pkgs/main/win-64::libtiff-4.5.1-h44ae7cf_1 \n",
      "  libuv              pkgs/main/win-64::libuv-1.48.0-h827c3e9_0 \n",
      "  libwebp-base       pkgs/main/win-64::libwebp-base-1.3.2-h3d04722_1 \n",
      "  lz4-c              pkgs/main/win-64::lz4-c-1.9.4-h2bbff1b_1 \n",
      "  markupsafe         pkgs/main/win-64::markupsafe-2.1.3-py312h2bbff1b_0 \n",
      "  mkl                pkgs/main/win-64::mkl-2023.1.0-h6b88ed4_46358 \n",
      "  mkl-service        pkgs/main/win-64::mkl-service-2.4.0-py312h2bbff1b_1 \n",
      "  mkl_fft            pkgs/main/win-64::mkl_fft-1.3.11-py312h827c3e9_0 \n",
      "  mkl_random         pkgs/main/win-64::mkl_random-1.2.8-py312h0158946_0 \n",
      "  mpmath             pkgs/main/win-64::mpmath-1.3.0-py312haa95532_0 \n",
      "  networkx           pkgs/main/win-64::networkx-3.2.1-py312haa95532_0 \n",
      "  numpy              pkgs/main/win-64::numpy-2.0.1-py312hfd52020_1 \n",
      "  numpy-base         pkgs/main/win-64::numpy-base-2.0.1-py312h4dde369_1 \n",
      "  openjpeg           pkgs/main/win-64::openjpeg-2.5.2-hae555c5_0 \n",
      "  pillow             pkgs/main/win-64::pillow-11.0.0-py312h096bfcc_1 \n",
      "  pysocks            pkgs/main/win-64::pysocks-1.7.1-py312haa95532_0 \n",
      "  pytorch            pytorch/win-64::pytorch-2.2.2-py3.12_cuda12.1_cudnn8_0 \n",
      "  pytorch-cuda       pytorch/win-64::pytorch-cuda-12.1-hde6ce7c_6 \n",
      "  pytorch-mutex      pytorch/noarch::pytorch-mutex-1.0-cuda \n",
      "  pyyaml             pkgs/main/win-64::pyyaml-6.0.2-py312h827c3e9_0 \n",
      "  requests           pkgs/main/win-64::requests-2.32.3-py312haa95532_1 \n",
      "  sympy              pkgs/main/win-64::sympy-1.13.2-py312haa95532_0 \n",
      "  tbb                pkgs/main/win-64::tbb-2021.8.0-h59b6b97_0 \n",
      "  torchaudio         pytorch/win-64::torchaudio-2.2.2-py312_cu121 \n",
      "  torchvision        pytorch/win-64::torchvision-0.17.2-py312_cu121 \n",
      "  urllib3            pkgs/main/win-64::urllib3-2.2.3-py312haa95532_0 \n",
      "  win_inet_pton      pkgs/main/win-64::win_inet_pton-1.1.0-py312haa95532_0 \n",
      "  yaml               pkgs/main/win-64::yaml-0.2.5-he774522_0 \n",
      "  zstd               pkgs/main/win-64::zstd-1.5.6-h8880b57_0 \n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages: ...working...\n",
      "pillow-11.0.0        | 901 KB    |            |   0% \n",
      "\n",
      "certifi-2024.12.14   | 162 KB    |            |   0% \u001b[A\n",
      "\n",
      "certifi-2024.12.14   | 162 KB    | ########## | 100% \u001b[A\n",
      "pillow-11.0.0        | 901 KB    | ########## | 100% \n",
      "\n",
      "certifi-2024.12.14   | 162 KB    | ########## | 100% \u001b[A\n",
      "\n",
      "certifi-2024.12.14   | 162 KB    | ########## | 100% \u001b[A\n",
      "pillow-11.0.0        | 901 KB    | ########## | 100% \n",
      "pillow-11.0.0        | 901 KB    | ########## | 100% \n",
      "                                                     \n",
      "\n",
      "\n",
      "                                                     \u001b[A done\n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "conda install pytorch==2.2.2 torchvision==0.17.2 torchaudio==2.2.2 pytorch-cuda=12.1 -c pytorch -c nvidia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2023 NVIDIA Corporation\n",
      "Built on Wed_Feb__8_05:53:42_Coordinated_Universal_Time_2023\n",
      "Cuda compilation tools, release 12.1, V12.1.66\n",
      "Build cuda_12.1.r12.1/compiler.32415258_0\n"
     ]
    }
   ],
   "source": [
    "!nvcc --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch 버전: 2.2.2\n",
      "CUDA 사용 가능 여부: True\n",
      "CUDA 버전: 12.1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"PyTorch 버전:\", torch.__version__)\n",
    "print(\"CUDA 사용 가능 여부:\", torch.cuda.is_available())\n",
    "print(\"CUDA 버전:\", torch.version.cuda)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numpy==1.26.4\n",
      "  Downloading numpy-1.26.4-cp312-cp312-win_amd64.whl.metadata (61 kB)\n",
      "Downloading numpy-1.26.4-cp312-cp312-win_amd64.whl (15.5 MB)\n",
      "   ---------------------------------------- 0.0/15.5 MB ? eta -:--:--\n",
      "   --------- ------------------------------ 3.7/15.5 MB 16.8 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 11.5/15.5 MB 30.1 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 13.6/15.5 MB 23.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 15.5/15.5 MB 20.8 MB/s eta 0:00:00\n",
      "Installing collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.0.1\n",
      "    Uninstalling numpy-2.0.1:\n",
      "      Successfully uninstalled numpy-2.0.1\n",
      "Successfully installed numpy-1.26.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\user\\anaconda3\\envs\\py3_11\\Lib\\site-packages\\~umpy'.\n",
      "  You can safely remove it manually.\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy==1.26.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA 사용 가능 여부: False\n",
      "현재 사용 device: cpu\n",
      "CUDA 버전: None\n",
      "GPU를 사용할 수 없습니다.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# CUDA 사용 가능 여부 확인\n",
    "print(\"CUDA 사용 가능 여부:\", torch.cuda.is_available())\n",
    "\n",
    "# 현재 사용 중인 device 확인\n",
    "print(\"현재 사용 device:\", torch.device('cuda' if torch.cuda.is_available() else 'cpu'))\n",
    "\n",
    "# CUDA 버전 확인\n",
    "print(\"CUDA 버전:\", torch.version.cuda)\n",
    "\n",
    "# GPU 이름 확인\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU 이름:\", torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    print(\"GPU를 사용할 수 없습니다.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.5.1+cpu\n",
      "CUDA available: False\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch 버전: 2.5.1+cpu\n",
      "CUDA 사용 가능 여부: False\n",
      "CUDA 버전: None\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"PyTorch 버전:\", torch.__version__)\n",
    "print(\"CUDA 사용 가능 여부:\", torch.cuda.is_available())\n",
    "print(\"CUDA 버전:\", torch.version.cuda)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall torch torchvision torchaudio  \n",
    "#!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3_11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
