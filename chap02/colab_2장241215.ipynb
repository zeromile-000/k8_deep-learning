{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8513fc08",
   "metadata": {},
   "source": [
    "PyTorch에서 **텐서(Tensor)**는 데이터를 표현하는 기본 단위입니다. 이는 다차원 배열(n-dimensional array)로, 딥러닝 모델의 입력, 출력, 가중치 등을 표현하고 연산하는 데 사용됩니다. 텐서는 NumPy의 배열과 유사하지만, GPU 가속을 활용할 수 있다는 점에서 차별화됩니다.\n",
    "\n",
    "텐서의 특징\n",
    "1. 다차원 배열\n",
    "\n",
    "텐서는 스칼라(0차원)부터 벡터(1차원), 행렬(2차원), 고차원 배열까지 표현할 수 있습니다.\n",
    "예를 들어:\n",
    "스칼라(0D 텐서): 5\n",
    "\n",
    "벡터(1D 텐서): [1,2,3]\n",
    "\n",
    "행렬(2D 텐서): [[1,2],[3,4]]\n",
    "\n",
    "텐서 (3D 텐서): 여러 개의 행렬이 쌓여 있는 구조. 교재 35페이지 그림\n",
    "\n",
    "2. GPU 가속 가능\n",
    "\n",
    "텐서는 CPU뿐 아니라 GPU에서도 연산이 가능합니다.\n",
    "GPU에서 연산하려면 텐서를 .to('cuda') 또는 .cuda()를 사용하여 GPU로 옮깁니다.\n",
    "\n",
    "3. 자동 미분 지원\n",
    "\n",
    "텐서는 PyTorch의 자동 미분(Autograd) 기능과 연동됩니다. 이를 통해 텐서 연산의 기울기를 자동으로 계산할 수 있습니다.\n",
    "예: requires_grad=True로 설정하면 텐서의 연산 기록을 저장하여 역전파(backpropagation)에 활용합니다.\n",
    "\n",
    "4. 다양한 자료형 지원\n",
    "\n",
    "PyTorch 텐서는 다양한 데이터 타입을 지원합니다 (e.g., float32, int64 등).\n",
    "예: torch.float, torch.int, torch.bool, torch.complex64 등.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "099ffddd",
   "metadata": {
    "id": "099ffddd"
   },
   "outputs": [],
   "source": [
    "##2.2.1 텐서 다루기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8cf51847",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torch in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (2.5.1)\n",
      "Requirement already satisfied: torchvision in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (0.20.1)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (2.5.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from torch) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from torch) (2024.10.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from torchvision) (2.1.3)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from torchvision) (11.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "kZRX92aQVHLF",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4692,
     "status": "ok",
     "timestamp": 1715838287186,
     "user": {
      "displayName": "Bonghee Hong",
      "userId": "17805293653427923937"
     },
     "user_tz": -540
    },
    "id": "kZRX92aQVHLF",
    "outputId": "51b480da-fda7-479a-8476-cb7ce1bc019a"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# 파이토치에서 텐서 표현 \u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      3\u001b[0m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;66;03m# false이면 CPU 사용 \u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "# 파이토치에서 텐서 표현 \n",
    "import torch\n",
    "torch.cuda.is_available() # false이면 CPU 사용 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a92d22",
   "metadata": {},
   "source": [
    "PyTorch의 **연산 그래프(Computational Graph)**는 딥러닝 모델 학습 과정에서 **자동 미분(Autograd)**을 가능하게 하는 핵심 구조입니다. 연산 그래프는 모델의 파라미터가 어떻게 입력 데이터에서 출력으로 전달되는지, 그리고 손실 함수가 어떻게 계산되는지를 나타내는 데이터의 연산 경로를 추적하는 구조입니다.\n",
    "\n",
    "연산 그래프는 딥러닝에서 중요한 역전파(Backpropagation) 과정을 자동화하기 위해 필요합니다. 딥러닝의 목표는 손실(loss)을 최소화하기 위해 모델 파라미터(예: 가중치 \n",
    "𝑤와 편향 𝑏)를 학습시키는 것입니다. 이를 위해 **기울기(Gradient)**를 계산해야 합니다. \n",
    "\n",
    "\n",
    "1.기울기 자동 계산\n",
    "\n",
    "PyTorch는 연산 그래프를 기반으로 기울기를 자동으로 계산합니다. 사용자가 직접 복잡한 미분 공식을 유도할 필요가 없습니다.\n",
    "예를 들어, \n",
    "\n",
    "L=(wx+b) **2\n",
    " 라는 손실 함수가 있을 때, 연산 그래프를 통해 \n",
    "기울기 2wx를 자동으로 계산합니다.\n",
    "\n",
    "2. 효율적인 역전파\n",
    "\n",
    "연산 그래프는 **체인 룰(Chain Rule)**을 적용하여 입력부터 출력까지 모든 연산의 미분을 효율적으로 계산합니다.\n",
    "역전파 과정에서 그래프의 각 연산 노드에서 기울기를 계산하고 전파합니다.\n",
    "\n",
    "3. 동적 계산 지원\n",
    "PyTorch는 **동적 연산 그래프(Dynamic Computational Graph)**를 사용합니다. 즉, 연산이 수행될 때 그래프가 실시간으로 생성됩니다.\n",
    "이런 동적 특성 덕분에 조건문, 반복문 등의 구조적인 변화가 있는 모델도 쉽게 정의할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0009e0b",
   "metadata": {},
   "source": [
    "연산 그래프의 용도\n",
    "1. 기울기 계산 (자동 미분)\n",
    "연산 그래프를 사용하면, 모델의 파라미터에 대한 손실 함수의 기울기를 자동으로 계산할 수 있습니다. PyTorch에서"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29182545",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 연산 그래프가 각 줄이 연결된다\n",
    "    \n",
    "import torch\n",
    "\n",
    "# requires_grad=True 설정된 텐서\n",
    "x = torch.tensor(2.0, requires_grad=True)\n",
    "w = torch.tensor(3.0, requires_grad=True)\n",
    "b = torch.tensor(1.0, requires_grad=True)\n",
    "\n",
    "# 연산 정의\n",
    "y = w * x + b\n",
    "loss = y ** 2  # 손실 함수\n",
    "\n",
    "# 역전파\n",
    "loss.backward()\n",
    "\n",
    "# 각 텐서의 기울기 출력\n",
    "print(w.grad)  # dy/dw\n",
    "print(x.grad)  # dy/dx\n",
    "print(b.grad)  # dy/db\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fcc9464",
   "metadata": {},
   "source": [
    "2. 딥러닝 학습(역전파 기반의 가중치 업데이트)\n",
    "연산 그래프는 딥러닝 모델의 학습 과정에서 손실 함수의 기울기를 계산하고, 이를 기반으로 가중치를 업데이트합니다.\n",
    "\n",
    "1.순전파(Forward Pass):\n",
    "입력 데이터를 연산 그래프를 따라 계산하여 출력(예측값)을 생성.\n",
    "2. 손실 계산:\n",
    "출력값과 실제 값 사이의 손실을 계산.\n",
    "3. 역전파(Backward Pass):\n",
    "연산 그래프를 따라 손실 함수의 기울기를 계산.\n",
    "4. 가중치 업데이트:\n",
    "기울기를 사용하여 경사하강법(Gradient Descent)으로 가중치를 업데이트."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0054917d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer를 활용한 가중치 업데이트\n",
    "optimizer = torch.optim.SGD([w, b], lr=0.01)\n",
    "\n",
    "# 역전파 후 가중치 업데이트\n",
    "optimizer.step()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a4661d2",
   "metadata": {},
   "source": [
    "2.2.1 텐서 다루기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "805e1388",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<built-in method type of Tensor object at 0x0000020B54A09A30>\n",
      "------------------------\n",
      "------------------------\n",
      "tensor([[1., 2.],\n",
      "        [3., 4.]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "import torch # GPU를 지원하는 텐서 패키지\n",
    "t = torch.tensor([[1,2],[3,4]]) # 텐서 객체를 만든다.\n",
    "print(t.type)\n",
    "print('------------------------')\n",
    "#print(torch.tensor([[1,2],[3,4]], device=\"cuda:0\")) #GPU가 없다면 오류가 발생하므로 주석 처리하였습니다.\n",
    "print('------------------------')\n",
    "\n",
    "print(torch.tensor([[1,2],[3,4]], dtype=torch.float64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "13955c29",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 313,
     "status": "ok",
     "timestamp": 1715838722984,
     "user": {
      "displayName": "Bonghee Hong",
      "userId": "17805293653427923937"
     },
     "user_tz": -540
    },
    "id": "13955c29",
    "outputId": "9bb7554d-bda0-4672-d1fb-1c21455ac0be"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2],\n",
      "        [3, 4]])\n",
      "[[1 2]\n",
      " [3 4]]\n",
      "cpu\n",
      "------------------------\n",
      "tensor([[1, 2],\n",
      "        [3, 4]])\n",
      "cpu\n",
      "[[1 2]\n",
      " [3 4]]\n"
     ]
    }
   ],
   "source": [
    "temp = torch.tensor([[1,2],[3,4]])\n",
    "print(temp)\n",
    "print(temp.numpy()) # 텐서를 ndarray로 변환\n",
    "print(temp.device) #device 속성을 확인\n",
    "print('------------------------')\n",
    "#temp = torch.tensor([[1,2],[3,4]], device=\"cuda:0\") #GPU가 없다면 오류가 발생하므로 주석 처리하였습니다.\n",
    "print(temp) #cpu tensor와 구분\n",
    "print(temp.device)  # 출력: cuda:0\n",
    "#print(temp.numpy()) # cuda tensor > ndarray로 변환 안된다\n",
    "#temp = torch.tensor([[1,2],[3,4]], device=\"cuda:0\")# GPU\n",
    "print(temp.to(\"cpu\").numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8018550e",
   "metadata": {},
   "source": [
    "텐서의 인덱스 조작 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ceaaed8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 307,
     "status": "ok",
     "timestamp": 1715838503672,
     "user": {
      "displayName": "Bonghee Hong",
      "userId": "17805293653427923937"
     },
     "user_tz": -540
    },
    "id": "4ceaaed8",
    "outputId": "39ad090a-b964-4636-c23a-851626c9ffb8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 2., 3., 4., 5., 6., 7.])\n",
      "tensor(1.) tensor(2.) tensor(7.)\n",
      "------------------------\n",
      "tensor([3., 4., 5.]) tensor([5., 6.])\n"
     ]
    }
   ],
   "source": [
    "temp = torch.FloatTensor([1, 2, 3, 4, 5, 6, 7])\n",
    "print(temp)\n",
    "print(temp[0], temp[1], temp[-1])\n",
    "print('------------------------')\n",
    "print(temp[2:5], temp[4:-1]) #넘파이 슬라이싱과 같다 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "h7Qp_dpVynFf",
   "metadata": {
    "id": "h7Qp_dpVynFf"
   },
   "source": [
    "텐서 연산 및 차원 조작"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "35d9751c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 924,
     "status": "ok",
     "timestamp": 1715730427854,
     "user": {
      "displayName": "Bonghee Hong",
      "userId": "17805293653427923937"
     },
     "user_tz": -540
    },
    "id": "35d9751c",
    "outputId": "4fea9e46-2239-4f0f-a5b8-89a5e8790bff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2, 2, 3])\n",
      "tensor([ 3,  8, 18])\n"
     ]
    }
   ],
   "source": [
    "v = torch.tensor([1, 2, 3])\n",
    "w = torch.tensor([3, 4, 6])\n",
    "print(w - v) # 벡터 연산\n",
    "print(w * v) # 벡터 연산 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "50d75b43",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 307,
     "status": "ok",
     "timestamp": 1715838843238,
     "user": {
      "displayName": "Bonghee Hong",
      "userId": "17805293653427923937"
     },
     "user_tz": -540
    },
    "id": "50d75b43",
    "outputId": "2f5b2f54-a9ed-4aa3-bbbb-e600bf538c7f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2])\n",
      "------------------------\n",
      "tensor([[1],\n",
      "        [2],\n",
      "        [3],\n",
      "        [4]])\n",
      "------------------------\n",
      "torch.Size([4])\n",
      "tensor([1, 2, 3, 4])\n",
      "------------------------\n",
      "tensor([[1, 2, 3, 4]])\n",
      "------------------------\n",
      "tensor([[1],\n",
      "        [2],\n",
      "        [3],\n",
      "        [4]])\n"
     ]
    }
   ],
   "source": [
    "temp = torch.tensor([\n",
    "    [1, 2], [3, 4]\n",
    "])\n",
    "\n",
    "print(temp.shape)\n",
    "print('------------------------')\n",
    "print(temp.view(4,1)) # (4,1)\n",
    "print('------------------------')\n",
    "t2= temp.view(-1) # [4] - 넘파이의 reshape()과 유사\n",
    "print(t2.shape)\n",
    "print(temp.view(-1)) # (4,) - 1차원 벡터로 변환 \n",
    "print('------------------------')\n",
    "print(temp.view(1, -1)) # (1,4) > (1, ?)로 변환\n",
    "print('------------------------')\n",
    "print(temp.view(-1, 1)) # (4,1) > (?, 1)로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "GS0fS9SBSXDE",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5376,
     "status": "ok",
     "timestamp": 1715730441865,
     "user": {
      "displayName": "Bonghee Hong",
      "userId": "17805293653427923937"
     },
     "user_tz": -540
    },
    "id": "GS0fS9SBSXDE",
    "outputId": "ad665f58-0b35-4fa4-f57b-a1293eafb113"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pandas in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.23.2 in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from pandas) (2.1.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip3 install pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "F-ziG5wEUSEr",
   "metadata": {
    "id": "F-ziG5wEUSEr"
   },
   "source": [
    "코랩에서 구글 드라이브를 mount한다\n",
    "경로복사로 파일 경로를 수정한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "Y1P77eHuSfX8",
   "metadata": {
    "id": "Y1P77eHuSfX8"
   },
   "outputs": [],
   "source": [
    "## csv 파일형태 불러오기\n",
    "import pandas as pd\n",
    "import torch\n",
    "data=pd.read_csv('../chap09/data/class2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "glcxHZezUgJS",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 307,
     "status": "ok",
     "timestamp": 1715839595705,
     "user": {
      "displayName": "Bonghee Hong",
      "userId": "17805293653427923937"
     },
     "user_tz": -540
    },
    "id": "glcxHZezUgJS",
    "outputId": "86319734-952a-4997-aec2-64dbbf1ed66c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0      id tissue class class2      x      y      r\n",
      "0           0  mdb000      C  CIRC      N  535.0  475.0  192.0\n",
      "1           1  mdb001      A  CIRA      N  433.0  268.0   58.0\n",
      "2           2  mdb002      A  CIRA      I    NaN    NaN    NaN\n",
      "3           3  mdb003      C  CIRC      B    NaN    NaN    NaN\n",
      "4           4  mdb004      F  CIRF      I  488.0  145.0   29.0\n",
      "5           5  mdb005      F  CIRF      B  544.0  178.0   26.0\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "38LHO7H3U6WV",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 633,
     "status": "ok",
     "timestamp": 1715773184157,
     "user": {
      "displayName": "Bonghee Hong",
      "userId": "17805293653427923937"
     },
     "user_tz": -540
    },
    "id": "38LHO7H3U6WV",
    "outputId": "0c8b686f-1352-44be-9d13-6de856983f5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[535.],\n",
      "        [433.],\n",
      "        [ nan],\n",
      "        [ nan],\n",
      "        [488.],\n",
      "        [544.]])\n"
     ]
    }
   ],
   "source": [
    "#왜 unsqueeze()를 하는가?\n",
    "x=torch.from_numpy(data['x'].values).unsqueeze(dim=1).float()\n",
    "y=torch.from_numpy(data['y'].values).unsqueeze(dim=1).float()\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a2a681",
   "metadata": {},
   "source": [
    "unsqueeze()는 PyTorch에서 텐서의 차원(dimension)을 추가하는 데 사용되는 메서드입니다. 즉, 기존 텐서의 특정 위치에 크기가 1인 차원을 삽입하여 텐서의 모양(shape)을 변경합니다.\n",
    "\n",
    "tensor.unsqueeze(dim)\n",
    "dim: 새로 추가할 차원의 위치를 지정합니다. 음수를 사용하면 뒤에서부터 차원을 계산합니다.\n",
    "결과: 지정된 위치에 크기가 1인 차원이 추가된 새로운 텐서를 반환합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3ccfe08c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3])\n",
      "torch.Size([3, 1])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "x = torch.tensor([1, 2, 3])  # x의 shape: (3,)\n",
    "x_unsqueezed = x.unsqueeze(0)  # dim=0에 차원을 추가\n",
    "print(x_unsqueezed.shape)  # 출력: torch.Size([1, 3])\n",
    "\n",
    "x_unsqueezed = x.unsqueeze(1)  # dim=1에 차원을 추가\n",
    "print(x_unsqueezed.shape)  # 출력: torch.Size([3, 1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "251b2afe",
   "metadata": {},
   "source": [
    "x.unsqueeze(0): (3,) → (1, 3) (배열의 맨 앞에 차원이 추가됨).\n",
    "x.unsqueeze(1): (3,) → (3, 1) (배열의 두 번째 차원에 추가됨)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e04895",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.from_numpy(data['x'].values).unsqueeze(dim=1).float()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97293322",
   "metadata": {},
   "source": [
    "1. torch.from_numpy(data['x'].values)\n",
    "data['x'].values: NumPy 배열 형태의 데이터를 PyTorch 텐서로 변환.\n",
    "예를 들어, data['x'].values의 형태가 (N,)라고 가정.\n",
    "\n",
    "2. .unsqueeze(dim=1)\n",
    "dim=1에 크기가 1인 차원을 추가.\n",
    "기존 텐서의 shape이 (N,)라면, unsqueeze(dim=1)의 결과는 (N, 1)이 됩니다.\n",
    "이 과정은 일반적으로 딥러닝 모델에 입력 데이터를 맞추기 위해 사용됩니다.\n",
    "(예: 입력 데이터가 2D 형태인 (N, 1)이 되어야 하는 경우)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b3634af",
   "metadata": {},
   "source": [
    "왜 unsqueeze(dim=1)이 필요한가?\n",
    "많은 딥러닝 모델은 2D 입력을 필요로 합니다. 특히, 선형 회귀나 MLP(Multi-Layer Perceptron) 같은 모델에서는 각 입력 데이터가 (N, D) 형태(즉, N개의 샘플에 대해 D차원 특성 벡터)여야 합니다.\n",
    "\n",
    "예를 들어:\n",
    "원래 데이터가 1D 텐서: [x1, x2, x3, ...] (shape: (N,)).\n",
    "이를 2D로 변경: [[x1], [x2], [x3], ...] (shape: (N, 1)).\n",
    "unsqueeze(dim=1)을 사용하여 2D 텐서로 확장합니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "401223d8",
   "metadata": {},
   "source": [
    "covtype.csv는 Covertype 데이터셋으로, 미국 콜로라도주의 국립공원의 토양 및 식생 유형을 예측하기 위한 표준 데이터셋입니다. 이 데이터셋은 UCI 머신러닝 저장소에 공개되어 있으며, CSV 형식으로 다운로드할 수 있습니다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a041531",
   "metadata": {},
   "source": [
    "Custom dataset을 만들어서 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9ZRkBKGQWuti",
   "metadata": {
    "id": "9ZRkBKGQWuti"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self,csv_file):\n",
    "      self.label=pd.read_csv(csv_file)\n",
    "\n",
    "    def __len__(self):\n",
    "      return len(self.label)\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "      sample=torch.tensor(self.label.iloc[idx,0:3]).int()\n",
    "      label=torch.tensor(self.label.iloc[idx,3]).int()\n",
    "      return sample, label\n",
    "\n",
    "tensor_dataset=CustomDataset('./data/COVTYPE.csv')\n",
    "dataset=DataLoader(tensor_dataset,batch_size=4,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "LeTag_R0E7B3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 291
    },
    "executionInfo": {
     "elapsed": 353,
     "status": "ok",
     "timestamp": 1715840738211,
     "user": {
      "displayName": "Bonghee Hong",
      "userId": "17805293653427923937"
     },
     "user_tz": -540
    },
    "id": "LeTag_R0E7B3",
    "outputId": "59f2ba07-ee93-4424-97ce-5d0b91772bd0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
       "      pre.function-repr-contents {\n",
       "        overflow-x: auto;\n",
       "        padding: 8px 12px;\n",
       "        max-height: 500px;\n",
       "      }\n",
       "\n",
       "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
       "        cursor: pointer;\n",
       "        max-height: 100px;\n",
       "      }\n",
       "    </style>\n",
       "    <pre style=\"white-space: initial; background:\n",
       "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
       "         border-bottom: 1px solid var(--colab-border-color);\"><b>torch.utils.data.dataloader.DataLoader</b><br/>def __init__(dataset: Dataset[T_co], batch_size: Optional[int]=1, shuffle: Optional[bool]=None, sampler: Union[Sampler, Iterable, None]=None, batch_sampler: Union[Sampler[List], Iterable[List], None]=None, num_workers: int=0, collate_fn: Optional[_collate_fn_t]=None, pin_memory: bool=False, drop_last: bool=False, timeout: float=0, worker_init_fn: Optional[_worker_init_fn_t]=None, multiprocessing_context=None, generator=None, *, prefetch_factor: Optional[int]=None, persistent_workers: bool=False, pin_memory_device: str=&#x27;&#x27;)</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py</a>Data loader combines a dataset and a sampler, and provides an iterable over the given dataset.\n",
       "\n",
       "The :class:`~torch.utils.data.DataLoader` supports both map-style and\n",
       "iterable-style datasets with single- or multi-process loading, customizing\n",
       "loading order and optional automatic batching (collation) and memory pinning.\n",
       "\n",
       "See :py:mod:`torch.utils.data` documentation page for more details.\n",
       "\n",
       "Args:\n",
       "    dataset (Dataset): dataset from which to load the data.\n",
       "    batch_size (int, optional): how many samples per batch to load\n",
       "        (default: ``1``).\n",
       "    shuffle (bool, optional): set to ``True`` to have the data reshuffled\n",
       "        at every epoch (default: ``False``).\n",
       "    sampler (Sampler or Iterable, optional): defines the strategy to draw\n",
       "        samples from the dataset. Can be any ``Iterable`` with ``__len__``\n",
       "        implemented. If specified, :attr:`shuffle` must not be specified.\n",
       "    batch_sampler (Sampler or Iterable, optional): like :attr:`sampler`, but\n",
       "        returns a batch of indices at a time. Mutually exclusive with\n",
       "        :attr:`batch_size`, :attr:`shuffle`, :attr:`sampler`,\n",
       "        and :attr:`drop_last`.\n",
       "    num_workers (int, optional): how many subprocesses to use for data\n",
       "        loading. ``0`` means that the data will be loaded in the main process.\n",
       "        (default: ``0``)\n",
       "    collate_fn (Callable, optional): merges a list of samples to form a\n",
       "        mini-batch of Tensor(s).  Used when using batched loading from a\n",
       "        map-style dataset.\n",
       "    pin_memory (bool, optional): If ``True``, the data loader will copy Tensors\n",
       "        into device/CUDA pinned memory before returning them.  If your data elements\n",
       "        are a custom type, or your :attr:`collate_fn` returns a batch that is a custom type,\n",
       "        see the example below.\n",
       "    drop_last (bool, optional): set to ``True`` to drop the last incomplete batch,\n",
       "        if the dataset size is not divisible by the batch size. If ``False`` and\n",
       "        the size of dataset is not divisible by the batch size, then the last batch\n",
       "        will be smaller. (default: ``False``)\n",
       "    timeout (numeric, optional): if positive, the timeout value for collecting a batch\n",
       "        from workers. Should always be non-negative. (default: ``0``)\n",
       "    worker_init_fn (Callable, optional): If not ``None``, this will be called on each\n",
       "        worker subprocess with the worker id (an int in ``[0, num_workers - 1]``) as\n",
       "        input, after seeding and before data loading. (default: ``None``)\n",
       "    multiprocessing_context (str or multiprocessing.context.BaseContext, optional): If\n",
       "        ``None``, the default `multiprocessing context`_ of your operating system will\n",
       "        be used. (default: ``None``)\n",
       "    generator (torch.Generator, optional): If not ``None``, this RNG will be used\n",
       "        by RandomSampler to generate random indexes and multiprocessing to generate\n",
       "        ``base_seed`` for workers. (default: ``None``)\n",
       "    prefetch_factor (int, optional, keyword-only arg): Number of batches loaded\n",
       "        in advance by each worker. ``2`` means there will be a total of\n",
       "        2 * num_workers batches prefetched across all workers. (default value depends\n",
       "        on the set value for num_workers. If value of num_workers=0 default is ``None``.\n",
       "        Otherwise, if value of ``num_workers &gt; 0`` default is ``2``).\n",
       "    persistent_workers (bool, optional): If ``True``, the data loader will not shut down\n",
       "        the worker processes after a dataset has been consumed once. This allows to\n",
       "        maintain the workers `Dataset` instances alive. (default: ``False``)\n",
       "    pin_memory_device (str, optional): the device to :attr:`pin_memory` to if ``pin_memory`` is\n",
       "        ``True``.\n",
       "\n",
       "\n",
       ".. warning:: If the ``spawn`` start method is used, :attr:`worker_init_fn`\n",
       "             cannot be an unpicklable object, e.g., a lambda function. See\n",
       "             :ref:`multiprocessing-best-practices` on more details related\n",
       "             to multiprocessing in PyTorch.\n",
       "\n",
       ".. warning:: ``len(dataloader)`` heuristic is based on the length of the sampler used.\n",
       "             When :attr:`dataset` is an :class:`~torch.utils.data.IterableDataset`,\n",
       "             it instead returns an estimate based on ``len(dataset) / batch_size``, with proper\n",
       "             rounding depending on :attr:`drop_last`, regardless of multi-process loading\n",
       "             configurations. This represents the best guess PyTorch can make because PyTorch\n",
       "             trusts user :attr:`dataset` code in correctly handling multi-process\n",
       "             loading to avoid duplicate data.\n",
       "\n",
       "             However, if sharding results in multiple workers having incomplete last batches,\n",
       "             this estimate can still be inaccurate, because (1) an otherwise complete batch can\n",
       "             be broken into multiple ones and (2) more than one batch worth of samples can be\n",
       "             dropped when :attr:`drop_last` is set. Unfortunately, PyTorch can not detect such\n",
       "             cases in general.\n",
       "\n",
       "             See `Dataset Types`_ for more details on these two types of datasets and how\n",
       "             :class:`~torch.utils.data.IterableDataset` interacts with\n",
       "             `Multi-process data loading`_.\n",
       "\n",
       ".. warning:: See :ref:`reproducibility`, and :ref:`dataloader-workers-random-seed`, and\n",
       "             :ref:`data-loading-randomness` notes for random seed related questions.\n",
       "\n",
       ".. _multiprocessing context:\n",
       "    https://docs.python.org/3/library/multiprocessing.html#contexts-and-start-methods</pre>\n",
       "      <script>\n",
       "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
       "        for (const element of document.querySelectorAll('.filepath')) {\n",
       "          element.style.display = 'block'\n",
       "          element.onclick = (event) => {\n",
       "            event.preventDefault();\n",
       "            event.stopPropagation();\n",
       "            google.colab.files.view(element.textContent, 124);\n",
       "          };\n",
       "        }\n",
       "      }\n",
       "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
       "        element.onclick = (event) => {\n",
       "          event.preventDefault();\n",
       "          event.stopPropagation();\n",
       "          element.classList.toggle('function-repr-contents-collapsed');\n",
       "        };\n",
       "      }\n",
       "      </script>\n",
       "      </div>"
      ],
      "text/plain": [
       "torch.utils.data.dataloader.DataLoader"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3a20a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 실행 금지!!! - 굉장히 오래 걸린다 \n",
    "# dataloader는 다음과 같이 반복실행하는 기능 => 실행시키지 않아야 함\n",
    "for i,data in enumerate(dataset,0):\n",
    "    print(i,end='')\n",
    "    batch=data[0]\n",
    "    print(batch.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf6aaf0",
   "metadata": {},
   "source": [
    "파이토치에서 제공하는 데이터셋 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "rUmwfd6_kvCq",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5807,
     "status": "ok",
     "timestamp": 1715773231058,
     "user": {
      "displayName": "Bonghee Hong",
      "userId": "17805293653427923937"
     },
     "user_tz": -540
    },
    "id": "rUmwfd6_kvCq",
    "outputId": "a582e146-cbd9-4a28-953a-3b05499a9b36"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting requests\n",
      "  Using cached requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting charset-normalizer<4,>=2 (from requests)\n",
      "  Downloading charset_normalizer-3.4.0-cp311-cp311-win_amd64.whl.metadata (34 kB)\n",
      "Collecting idna<4,>=2.5 (from requests)\n",
      "  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests)\n",
      "  Using cached urllib3-2.2.3-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests)\n",
      "  Downloading certifi-2024.12.14-py3-none-any.whl.metadata (2.3 kB)\n",
      "Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Downloading certifi-2024.12.14-py3-none-any.whl (164 kB)\n",
      "   ---------------------------------------- 0.0/164.9 kB ? eta -:--:--\n",
      "   ----------------------------- ---------- 122.9/164.9 kB 3.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 164.9/164.9 kB 3.3 MB/s eta 0:00:00\n",
      "Downloading charset_normalizer-3.4.0-cp311-cp311-win_amd64.whl (101 kB)\n",
      "   ---------------------------------------- 0.0/101.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 101.8/101.8 kB 6.1 MB/s eta 0:00:00\n",
      "Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
      "Using cached urllib3-2.2.3-py3-none-any.whl (126 kB)\n",
      "Installing collected packages: urllib3, idna, charset-normalizer, certifi, requests\n",
      "Successfully installed certifi-2024.12.14 charset-normalizer-3.4.0 idna-3.10 requests-2.32.3 urllib3-2.2.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip3 install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7423e510",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torch in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (2.5.1)\n",
      "Requirement already satisfied: torchvision in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (0.20.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from torch) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from torch) (2024.10.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from torchvision) (2.1.3)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from torchvision) (11.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from jinja2->torch) (3.0.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip3 uninstall torch torchvision\n",
    "!pip3 install torch torchvision\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a99daa6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.1+cpu\n",
      "0.20.1+cpu\n"
     ]
    }
   ],
   "source": [
    "import torch # 텐서 정의\n",
    "import torchvision # 내장된 이미지\n",
    "\n",
    "print(torch.__version__)         # PyTorch 버전 출력\n",
    "print(torchvision.__version__)   # torchvision 버전 출력\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "V6n5xvrSk7m6",
   "metadata": {
    "id": "V6n5xvrSk7m6"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torchvision'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransforms\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtransforms\u001b[39;00m\n\u001b[0;32m      4\u001b[0m mnist_transform \u001b[38;5;241m=\u001b[39m transforms\u001b[38;5;241m.\u001b[39mCompose([\n\u001b[0;32m      5\u001b[0m     transforms\u001b[38;5;241m.\u001b[39mToTensor(),\n\u001b[0;32m      6\u001b[0m     transforms\u001b[38;5;241m.\u001b[39mNormalize((\u001b[38;5;241m0.5\u001b[39m,),(\u001b[38;5;241m1.0\u001b[39m,))\n\u001b[0;32m      7\u001b[0m     ])\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torchvision'"
     ]
    }
   ],
   "source": [
    "import torchvision # 내장된 이미지\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "mnist_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,),(1.0,))\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fTpwWvg5liXj",
   "metadata": {
    "id": "fTpwWvg5liXj"
   },
   "outputs": [],
   "source": [
    "from torchvision.datasets import MNIST\n",
    "import requests\n",
    "download_root = '/content/drive/MyDrive/Colab Notebooks/파이토치/pytorch2023/chap02/data/MNIST_DATASET'\n",
    "\n",
    "train_dataset = MNIST(download_root, transform=mnist_transform, train=True, download=True)\n",
    "valid_dataset = MNIST(download_root, transform=mnist_transform, train=False, download=True)\n",
    "test_dataset = MNIST(download_root, transform=mnist_transform, train=False, download=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "KD-uI2jmm-Vo",
   "metadata": {
    "id": "KD-uI2jmm-Vo"
   },
   "source": [
    "2.2.3 모델 정의\n",
    "\n",
    "단순 신경망 정의하는 방법"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eabe83df",
   "metadata": {},
   "source": [
    "# import torch # 텐서 정의\n",
    "# import torchvision # 내장된 이미지\n",
    "# import torch.nn as nn 신경망\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1EZYoRRPmylO",
   "metadata": {
    "id": "1EZYoRRPmylO"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "model = nn.Linear(in_features=1, out_features=1, bias=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a0690a8",
   "metadata": {},
   "source": [
    "torch.nn.Module은 PyTorch에서 신경망 모델을 정의할 때 사용하는 기본 클래스입니다. 이 클래스는 모델의 구조를 정의하고, 모델을 학습하고 평가할 때 필요한 메소드를 제공합니다. forward() 메소드는 모델의 전방향 패스(forward pass) 를 정의하는 데 사용됩니다. 즉, 데이터를 모델에 통과시켜 예측을 만드는 과정입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "u5jtlKZrm602",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 516,
     "status": "ok",
     "timestamp": 1715843179197,
     "user": {
      "displayName": "Bonghee Hong",
      "userId": "17805293653427923937"
     },
     "user_tz": -540
    },
    "id": "u5jtlKZrm602",
    "outputId": "3a281f83-4c2c-4697-8571-9dbc26b27ac9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.8603]], grad_fn=<SigmoidBackward0>)\n",
      "[[0.860302746295929]]\n"
     ]
    }
   ],
   "source": [
    "class MLP(nn.Module): # MLP의 Superclass 가 nn.Module이다.\n",
    "  def __init__(self, inputs):\n",
    "    super(MLP, self).__init__()\n",
    "    self.layer = nn.Linear(inputs, 1)\n",
    "    self.activation = nn.Sigmoid()\n",
    "\n",
    "  def forward(self, X):# forward 메소드는 모델이 입력 데이터를 어떻게 처리할지 정의\n",
    "    X = self.layer(X)\n",
    "    X = self.activation(X)\n",
    "    return X\n",
    "data = torch.tensor([1, 2, 3,4,5,6,7,8,9], dtype=torch.float32).unsqueeze(0)  # 텐서 크기를 바꾸어 실행\n",
    "model = MLP(len(data[0]))  # 입력의 차원을 데이터의 길이로\n",
    "output = model(data) # 학습 객체: forward가 data를 x로 받아서 처리\n",
    "print(output)\n",
    "print(output.tolist())  # 모델의 출력을 리스트로\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Q39CVdKV2DRE",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 277,
     "status": "ok",
     "timestamp": 1715773256089,
     "user": {
      "displayName": "Bonghee Hong",
      "userId": "17805293653427923937"
     },
     "user_tz": -540
    },
    "id": "Q39CVdKV2DRE",
    "outputId": "b69d5165-01d3-422e-9821-356a240faf63"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2049, 0.0000, 0.5761, 0.0033, 0.1592, 0.4973, 0.0000, 0.0000, 0.3434,\n",
      "         0.0000],\n",
      "        [0.1851, 0.0000, 0.5429, 0.1103, 0.0000, 0.3208, 0.0000, 0.0152, 0.4541,\n",
      "         0.0000],\n",
      "        [0.1462, 0.0000, 0.4717, 0.0429, 0.0000, 0.3419, 0.0510, 0.0070, 0.3087,\n",
      "         0.0000]], grad_fn=<ReluBackward0>)\n"
     ]
    }
   ],
   "source": [
    "class MLP(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(MLP, self).__init__()\n",
    "    self.layer1 = nn.Sequential( # 순차진행\n",
    "        nn.Conv2d(in_channels=3, out_channels=64, kernel_size=5),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.MaxPool2d(2))\n",
    "\n",
    "    self.layer2 = nn.Sequential(\n",
    "        nn.Conv2d(in_channels=64, out_channels=30, kernel_size=5),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.MaxPool2d(2))\n",
    "\n",
    "    self.layer3 = nn.Sequential(\n",
    "        nn.Linear(in_features=30*5*5, out_features=10, bias=True),\n",
    "        nn.ReLU(inplace=True))\n",
    "\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = self.layer1(x)\n",
    "    x = self.layer2(x)\n",
    "    x = x.view(x.shape[0],-1)\n",
    "    x = self.layer3(x)\n",
    "    return x\n",
    "\n",
    "model = MLP()\n",
    "data = torch.randn(3, 3, 32, 32)  # 3개의 이미지를 생성합니다. 각 이미지는 3채널(RGB)이며, 크기는 32x32입니다.\n",
    "model = MLP()  # 입력의 차원을 데이터의 길이로\n",
    "output = model(data)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec339731",
   "metadata": {},
   "source": [
    "forward() 메소드를 정의하면, 모델을 호출하는 것만으로 이 메소드가 자동으로 실행됩니다. 예를 들어, model(x)와 같이 호출하면 forward() 메소드가 실행됩니다.\n",
    "\n",
    "nn.Module 클래스는 PyTorch에서 신경망 모델을 정의할 때 사용하는 기본 클래스입니다. 이 클래스는 모델의 구조(Layer 정의)와 동작(Forward Pass)을 정의할 수 있는 메소드들을 제공합니다. forward() 메소드는 바로 이 동작을 정의하는 곳입니다.\n",
    "\n",
    "우리가 model(input_data)라고 호출할 때, PyTorch는 자동으로 forward() 메소드를 실행합니다. 이 호출은 다음과 같은 일련의 과정을 통해 이루어집니다:\n",
    "\n",
    "output = model(input_data)\n",
    "\n",
    "모델을 호출하는 model(input_data)는 __call__() 메소드를 트리거합니다.\n",
    "nn.Module은 __call__() 메소드를 오버라이드(재정의)한 클래스입니다. 이 메소드는 실제로 forward() 메소드를 호출합니다.\n",
    "\n",
    "nn.Module.__call__(self, *input, **kwargs)는 아래와 같은 작업을 수행합니다:\n",
    "forward() 메소드 호출: __call__()는 인스턴스가 호출될 때, 내부적으로 forward() 메소드를 호출합니다.\n",
    "추가적인 작업: __call__() 메소드는 추후 필요에 따라 여러 후처리 작업을 수행할 수 있습니다 (예: training 모드에서의 동작 제어 등).\n",
    "따라서, model(input_data)는 사실 model.__call__(input_data) 와 같으며, 내부적으로 model.forward(input_data) 를 실행합니다.\n",
    "\n",
    "orward() 메소드는 model(input_data)에서 자동으로 호출되며, 여기서 정의된 모델의 연산 흐름을 처리합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4w8Llw5iFWMR",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 288,
     "status": "ok",
     "timestamp": 1715773262923,
     "user": {
      "displayName": "Bonghee Hong",
      "userId": "17805293653427923937"
     },
     "user_tz": -540
    },
    "id": "4w8Llw5iFWMR",
    "outputId": "24a8507a-8e6f-46bc-8ce6-6639136a09ca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 1])\n",
      "tensor([[ 0.1909],\n",
      "        [ 0.3166],\n",
      "        [ 0.7593],\n",
      "        [ 0.7247],\n",
      "        [-0.2971],\n",
      "        [ 0.6199],\n",
      "        [ 0.6477],\n",
      "        [ 0.1744],\n",
      "        [ 0.7534],\n",
      "        [-0.1133]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "def MLP(in_features=1, hidden_features=20, out_features=1):\n",
    "    hidden = nn.Linear(in_features=in_features, out_features=hidden_features, bias=True)\n",
    "    activation = nn.ReLU()\n",
    "    output = nn.Linear(in_features=hidden_features, out_features=out_features, bias=True)\n",
    "    net = nn.Sequential(hidden, activation, output)\n",
    "    return net\n",
    "\n",
    "# 데이터 준비\n",
    "data = torch.randn(10, 1)  # 예시로 10개의 데이터 포인트를 생성합니다.\n",
    "print(data.shape)\n",
    "# 모델 생성\n",
    "model = MLP()\n",
    "\n",
    "# 모델 호출\n",
    "output = model(data) #data.shape = (10,1)이므로 in_features는 10이 되고 10개의 입력을 받아들임\n",
    "#  model(data)를 호출하면, MLP 클래스의 forward 메서드가 호출되면서\n",
    "##입력 데이터가 전달되고, 해당 입력 데이터에 대한 연산이 수행되어 출력이 생성됩니다.\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "NKD_8M96Qxp4",
   "metadata": {
    "id": "NKD_8M96Qxp4"
   },
   "source": [
    "2.2.4 모델 파라미터 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Fg5TyyvBQ2Zt",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 356
    },
    "executionInfo": {
     "elapsed": 272,
     "status": "error",
     "timestamp": 1715773784970,
     "user": {
      "displayName": "Bonghee Hong",
      "userId": "17805293653427923937"
     },
     "user_tz": -540
    },
    "id": "Fg5TyyvBQ2Zt",
    "outputId": "7c50a3e6-e570-4d80-f70d-45cf122fdb77"
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'DataLoader' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-ca1efd48c502>\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    629\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 631\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    632\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    673\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 675\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    676\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'DataLoader' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "### 교재 56페이지: 모델 파라미터 코드\n",
    "from torch.optim import optimizer\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer=optimizer,\n",
    "                                              lr_lambda=lambda epoch: 0.95**epoch)\n",
    "batch_size = 32\n",
    "\n",
    "# DataLoader 정의\n",
    "#dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "for epoch in range(1, 100+1):\n",
    "    model.train()\n",
    "    for x, y in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(x)\n",
    "        loss = criterion(outputs, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "w0M8bOtPE0Pm",
   "metadata": {
    "id": "w0M8bOtPE0Pm"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "GZ8ZUtIkSr6o",
   "metadata": {
    "id": "GZ8ZUtIkSr6o"
   },
   "outputs": [],
   "source": [
    "from torch.optim import optimizer\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import SGD, lr_scheduler\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# 데이터셋과 데이터로더를 정의해야 합니다.\n",
    "# 예를 들어, 단순한 데이터셋을 만들고 데이터로더를 생성할 수 있습니다.\n",
    "class SimpleDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n",
    "\n",
    "# 예제 데이터를 생성합니다.\n",
    "data = [(torch.randn(1), torch.randn(1)) for _ in range(100)]\n",
    "# 데이터셋을 생성합니다.\n",
    "dataset = SimpleDataset(data)\n",
    "# 데이터로더를 생성합니다.\n",
    "dataloader = DataLoader(dataset, batch_size=10, shuffle=True)\n",
    "\n",
    "# 모델을 생성합니다.\n",
    "def MLP(in_features=1, hidden_features=20, out_features=1):\n",
    "    hidden = nn.Linear(in_features=in_features, out_features=hidden_features, bias=True)\n",
    "    activation = nn.ReLU()\n",
    "    output = nn.Linear(in_features=hidden_features, out_features=out_features, bias=True)\n",
    "    net = nn.Sequential(hidden, activation, output)\n",
    "    return net\n",
    "\n",
    "# 모델을 생성합니다.\n",
    "model = MLP()\n",
    "\n",
    "# 손실 함수를 정의합니다.\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# 옵티마이저를 정의합니다.\n",
    "optimizer = SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "# 스케줄러를 정의합니다.\n",
    "scheduler = lr_scheduler.LambdaLR(optimizer, lr_lambda=lambda epoch: 0.95**epoch)\n",
    "\n",
    "# 모델 훈련 교재 57페이지\n",
    "for epoch in range(1, 100+1):\n",
    "    for x, y in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(model(x), y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    scheduler.step()\n",
    "\n",
    "# 학습 후의 모델을 사용하여 예측을 수행할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "uX4zgvP4S-tG",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 337,
     "status": "ok",
     "timestamp": 1715845783636,
     "user": {
      "displayName": "Bonghee Hong",
      "userId": "17805293653427923937"
     },
     "user_tz": -540
    },
    "id": "uX4zgvP4S-tG",
    "outputId": "295f3bfd-97fc-4479-ba50-816465385334"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(tensor([0.5705]), tensor([1.2116])), (tensor([0.1113]), tensor([-0.7853])), (tensor([-0.3382]), tensor([-1.3136])), (tensor([-0.2250]), tensor([-1.1769])), (tensor([0.3211]), tensor([0.0980])), (tensor([0.0604]), tensor([-0.6976])), (tensor([-0.4376]), tensor([0.1561])), (tensor([-2.8135]), tensor([-1.6216])), (tensor([-0.4019]), tensor([0.5546])), (tensor([-0.4785]), tensor([-0.4872]))]\n",
      "Input: tensor([0.5705])\n",
      "Actual Output: tensor([1.2116])\n",
      "Predicted Output: tensor([-0.1021])\n",
      "Input: tensor([0.1113])\n",
      "Actual Output: tensor([-0.7853])\n",
      "Predicted Output: tensor([-0.0411])\n",
      "Input: tensor([-0.3382])\n",
      "Actual Output: tensor([-1.3136])\n",
      "Predicted Output: tensor([0.0360])\n",
      "Input: tensor([-0.2250])\n",
      "Actual Output: tensor([-1.1769])\n",
      "Predicted Output: tensor([0.0127])\n",
      "Input: tensor([0.3211])\n",
      "Actual Output: tensor([0.0980])\n",
      "Predicted Output: tensor([-0.0647])\n",
      "Input: tensor([0.0604])\n",
      "Actual Output: tensor([-0.6976])\n",
      "Predicted Output: tensor([-0.0354])\n",
      "Input: tensor([-0.4376])\n",
      "Actual Output: tensor([0.1561])\n",
      "Predicted Output: tensor([0.0542])\n",
      "Input: tensor([-2.8135])\n",
      "Actual Output: tensor([-1.6216])\n",
      "Predicted Output: tensor([0.3096])\n",
      "Input: tensor([-0.4019])\n",
      "Actual Output: tensor([0.5546])\n",
      "Predicted Output: tensor([0.0491])\n",
      "Input: tensor([-0.4785])\n",
      "Actual Output: tensor([-0.4872])\n",
      "Predicted Output: tensor([0.0593])\n"
     ]
    }
   ],
   "source": [
    "# 예측을 수행할 테스트 데이터를 정의합니다.\n",
    "test_data = [(torch.randn(1), torch.randn(1)) for _ in range(10)]\n",
    "print(test_data)\n",
    "# 모델을 평가 모드로 설정합니다.\n",
    "model.eval()\n",
    "\n",
    "# 각 테스트 데이터에 대한 예측을 수행합니다.\n",
    "with torch.no_grad():  # 그라디언트 계산 비활성화\n",
    "    for x_test, y_test in test_data:\n",
    "        # 입력 데이터를 모델에 전달하여 예측을 수행합니다.\n",
    "        predicted_output = model(x_test)\n",
    "        print(\"Input:\", x_test)\n",
    "        print(\"Actual Output:\", y_test)\n",
    "        print(\"Predicted Output:\", predicted_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "_-u-7Gt_UBIe",
   "metadata": {
    "id": "_-u-7Gt_UBIe"
   },
   "source": [
    "모델평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ARr32BLLUD1a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 122670,
     "status": "ok",
     "timestamp": 1715744174721,
     "user": {
      "displayName": "Bonghee Hong",
      "userId": "17805293653427923937"
     },
     "user_tz": -540
    },
    "id": "ARr32BLLUD1a",
    "outputId": "307bff9a-a067-46ce-eaa1-cb0bde4ca220"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchmetrics\n",
      "  Downloading torchmetrics-1.4.0-py3-none-any.whl (868 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m868.8/868.8 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (1.25.2)\n",
      "Requirement already satisfied: packaging>17.1 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (24.0)\n",
      "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (2.2.1+cu121)\n",
      "Collecting lightning-utilities>=0.8.0 (from torchmetrics)\n",
      "  Downloading lightning_utilities-0.11.2-py3-none-any.whl (26 kB)\n",
      "Collecting pretty-errors==1.2.25 (from torchmetrics)\n",
      "  Downloading pretty_errors-1.2.25-py3-none-any.whl (17 kB)\n",
      "Collecting colorama (from pretty-errors==1.2.25->torchmetrics)\n",
      "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (67.7.2)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.11.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (3.14.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (3.3)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (2023.6.0)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.10.0->torchmetrics)\n",
      "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.10.0->torchmetrics)\n",
      "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.10.0->torchmetrics)\n",
      "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
      "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.10.0->torchmetrics)\n",
      "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
      "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.10.0->torchmetrics)\n",
      "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
      "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.10.0->torchmetrics)\n",
      "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
      "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.10.0->torchmetrics)\n",
      "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
      "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.10.0->torchmetrics)\n",
      "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
      "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.10.0->torchmetrics)\n",
      "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
      "Collecting nvidia-nccl-cu12==2.19.3 (from torch>=1.10.0->torchmetrics)\n",
      "  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
      "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.10.0->torchmetrics)\n",
      "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
      "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (2.2.0)\n",
      "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->torchmetrics)\n",
      "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->torchmetrics) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->torchmetrics) (1.3.0)\n",
      "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, lightning-utilities, colorama, pretty-errors, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torchmetrics\n",
      "Successfully installed colorama-0.4.6 lightning-utilities-0.11.2 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105 pretty-errors-1.2.25 torchmetrics-1.4.0\n"
     ]
    }
   ],
   "source": [
    "!pip install torchmetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "XWl_6kAhUK3z",
   "metadata": {
    "id": "XWl_6kAhUK3z"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchmetrics\n",
    "\n",
    "preds = torch.randn(10,5).softmax(dim=-1)\n",
    "target = torch.randint(5, (10,))\n",
    "num_classes = preds.size(1)  # preds 텐서의 마지막 차원의 크기를 가져옴\n",
    "#acc = torchmetrics.functional.accuracy(preds, target)\n",
    "acc = torchmetrics.functional.accuracy(preds, target, task=\"MULTICLASS\", num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "CnGTKD6DUyUF",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1715745027026,
     "user": {
      "displayName": "Bonghee Hong",
      "userId": "17805293653427923937"
     },
     "user_tz": -540
    },
    "id": "CnGTKD6DUyUF",
    "outputId": "49a104dd-b171-4d49-b9be-6ead0f8ddbe8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on batch 0: 0.30000001192092896\n",
      "Accuracy on batch 1: 0.30000001192092896\n",
      "Accuracy on batch 2: 0.10000000149011612\n",
      "Accuracy on batch 3: 0.30000001192092896\n",
      "Accuracy on batch 4: 0.10000000149011612\n",
      "Accuracy on batch 5: 0.10000000149011612\n",
      "Accuracy on batch 6: 0.10000000149011612\n",
      "Accuracy on batch 7: 0.20000000298023224\n",
      "Accuracy on batch 8: 0.0\n",
      "Accuracy on batch 9: 0.10000000149011612\n",
      "Accuracy on all data 0.1599999964237213\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchmetrics\n",
    "num_classes = 5\n",
    "metric = torchmetrics.Accuracy(task=\"multiclass\", num_classes=num_classes)\n",
    "#metric = torchmetrics.Accuracy(task=\"multiclass\")\n",
    "\n",
    "n_batches = 10\n",
    "for i in range(n_batches):\n",
    "    preds = torch.randn(10,5).softmax(dim=-1)\n",
    "    target = torch.randint(5, (10,))\n",
    "\n",
    "    acc = metric(preds, target)\n",
    "    print(f\"Accuracy on batch {i}: {acc}\")\n",
    "\n",
    "acc = metric.compute()\n",
    "print(f\"Accuracy on all data {acc}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aS450QIM714i",
   "metadata": {
    "id": "aS450QIM714i"
   },
   "source": [
    "훈련과정 모니터링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mOuZaGIL7412",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12547,
     "status": "ok",
     "timestamp": 1715771278437,
     "user": {
      "displayName": "Bonghee Hong",
      "userId": "17805293653427923937"
     },
     "user_tz": -540
    },
    "id": "mOuZaGIL7412",
    "outputId": "62ea6da7-52ce-4d03-ef13-017b9ebdc8d0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (2.15.2)\n",
      "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.4.0)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.63.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (2.27.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.2.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.6)\n",
      "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.25.2)\n",
      "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.20.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (2.31.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (67.7.2)\n",
      "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.16.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.0.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (5.3.3)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (0.4.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard) (2024.2.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard) (2.1.5)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard) (0.6.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard) (3.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "kNJCuYN78JSd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 211
    },
    "executionInfo": {
     "elapsed": 557,
     "status": "error",
     "timestamp": 1715772152456,
     "user": {
      "displayName": "Bonghee Hong",
      "userId": "17805293653427923937"
     },
     "user_tz": -540
    },
    "id": "kNJCuYN78JSd",
    "outputId": "a8ae6cd1-b3f2-467b-cda5-ed9d5cf86bd8"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-f6997dc9e1cf>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mbatch_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter(\"/content/drive/MyDrive/Colab Notebooks/파이토치/pytorch2023/chap02/tensorboard\")\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    batch_loss = 0.0\n",
    "\n",
    "    for i, (x,y) in enumerate(dataloader):\n",
    "        x,y = x.to(device).float(), y.to(device).float()\n",
    "        outputs = model(x)\n",
    "        loss = criterion(outputs, y)\n",
    "        writer.add_scalaer(\"Loss\", loss, epoch)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "writer.cloase()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e98bca",
   "metadata": {
    "id": "42e98bca"
   },
   "outputs": [],
   "source": [
    "#2.4 파이토치 코드 맛보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rwU1nKseYS27",
   "metadata": {
    "id": "rwU1nKseYS27"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44961535",
   "metadata": {
    "id": "44961535"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb364a0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 77
    },
    "executionInfo": {
     "elapsed": 33709,
     "status": "ok",
     "timestamp": 1715847823458,
     "user": {
      "displayName": "Bonghee Hong",
      "userId": "17805293653427923937"
     },
     "user_tz": -540
    },
    "id": "4fb364a0",
    "outputId": "e33dc709-5903-4240-96d5-6aa52bfe8bfa"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-b3a6bee2-1625-4c38-8126-2a5f5754deac\" name=\"files[]\" multiple disabled\n",
       "        style=\"border:none\" />\n",
       "     <output id=\"result-b3a6bee2-1625-4c38-8126-2a5f5754deac\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script>// Copyright 2017 Google LLC\n",
       "//\n",
       "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
       "// you may not use this file except in compliance with the License.\n",
       "// You may obtain a copy of the License at\n",
       "//\n",
       "//      http://www.apache.org/licenses/LICENSE-2.0\n",
       "//\n",
       "// Unless required by applicable law or agreed to in writing, software\n",
       "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
       "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
       "// See the License for the specific language governing permissions and\n",
       "// limitations under the License.\n",
       "\n",
       "/**\n",
       " * @fileoverview Helpers for google.colab Python module.\n",
       " */\n",
       "(function(scope) {\n",
       "function span(text, styleAttributes = {}) {\n",
       "  const element = document.createElement('span');\n",
       "  element.textContent = text;\n",
       "  for (const key of Object.keys(styleAttributes)) {\n",
       "    element.style[key] = styleAttributes[key];\n",
       "  }\n",
       "  return element;\n",
       "}\n",
       "\n",
       "// Max number of bytes which will be uploaded at a time.\n",
       "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
       "\n",
       "function _uploadFiles(inputId, outputId) {\n",
       "  const steps = uploadFilesStep(inputId, outputId);\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  // Cache steps on the outputElement to make it available for the next call\n",
       "  // to uploadFilesContinue from Python.\n",
       "  outputElement.steps = steps;\n",
       "\n",
       "  return _uploadFilesContinue(outputId);\n",
       "}\n",
       "\n",
       "// This is roughly an async generator (not supported in the browser yet),\n",
       "// where there are multiple asynchronous steps and the Python side is going\n",
       "// to poll for completion of each step.\n",
       "// This uses a Promise to block the python side on completion of each step,\n",
       "// then passes the result of the previous step as the input to the next step.\n",
       "function _uploadFilesContinue(outputId) {\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  const steps = outputElement.steps;\n",
       "\n",
       "  const next = steps.next(outputElement.lastPromiseValue);\n",
       "  return Promise.resolve(next.value.promise).then((value) => {\n",
       "    // Cache the last promise value to make it available to the next\n",
       "    // step of the generator.\n",
       "    outputElement.lastPromiseValue = value;\n",
       "    return next.value.response;\n",
       "  });\n",
       "}\n",
       "\n",
       "/**\n",
       " * Generator function which is called between each async step of the upload\n",
       " * process.\n",
       " * @param {string} inputId Element ID of the input file picker element.\n",
       " * @param {string} outputId Element ID of the output display.\n",
       " * @return {!Iterable<!Object>} Iterable of next steps.\n",
       " */\n",
       "function* uploadFilesStep(inputId, outputId) {\n",
       "  const inputElement = document.getElementById(inputId);\n",
       "  inputElement.disabled = false;\n",
       "\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  outputElement.innerHTML = '';\n",
       "\n",
       "  const pickedPromise = new Promise((resolve) => {\n",
       "    inputElement.addEventListener('change', (e) => {\n",
       "      resolve(e.target.files);\n",
       "    });\n",
       "  });\n",
       "\n",
       "  const cancel = document.createElement('button');\n",
       "  inputElement.parentElement.appendChild(cancel);\n",
       "  cancel.textContent = 'Cancel upload';\n",
       "  const cancelPromise = new Promise((resolve) => {\n",
       "    cancel.onclick = () => {\n",
       "      resolve(null);\n",
       "    };\n",
       "  });\n",
       "\n",
       "  // Wait for the user to pick the files.\n",
       "  const files = yield {\n",
       "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
       "    response: {\n",
       "      action: 'starting',\n",
       "    }\n",
       "  };\n",
       "\n",
       "  cancel.remove();\n",
       "\n",
       "  // Disable the input element since further picks are not allowed.\n",
       "  inputElement.disabled = true;\n",
       "\n",
       "  if (!files) {\n",
       "    return {\n",
       "      response: {\n",
       "        action: 'complete',\n",
       "      }\n",
       "    };\n",
       "  }\n",
       "\n",
       "  for (const file of files) {\n",
       "    const li = document.createElement('li');\n",
       "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
       "    li.append(span(\n",
       "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
       "        `last modified: ${\n",
       "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
       "                                    'n/a'} - `));\n",
       "    const percent = span('0% done');\n",
       "    li.appendChild(percent);\n",
       "\n",
       "    outputElement.appendChild(li);\n",
       "\n",
       "    const fileDataPromise = new Promise((resolve) => {\n",
       "      const reader = new FileReader();\n",
       "      reader.onload = (e) => {\n",
       "        resolve(e.target.result);\n",
       "      };\n",
       "      reader.readAsArrayBuffer(file);\n",
       "    });\n",
       "    // Wait for the data to be ready.\n",
       "    let fileData = yield {\n",
       "      promise: fileDataPromise,\n",
       "      response: {\n",
       "        action: 'continue',\n",
       "      }\n",
       "    };\n",
       "\n",
       "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
       "    let position = 0;\n",
       "    do {\n",
       "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
       "      const chunk = new Uint8Array(fileData, position, length);\n",
       "      position += length;\n",
       "\n",
       "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
       "      yield {\n",
       "        response: {\n",
       "          action: 'append',\n",
       "          file: file.name,\n",
       "          data: base64,\n",
       "        },\n",
       "      };\n",
       "\n",
       "      let percentDone = fileData.byteLength === 0 ?\n",
       "          100 :\n",
       "          Math.round((position / fileData.byteLength) * 100);\n",
       "      percent.textContent = `${percentDone}% done`;\n",
       "\n",
       "    } while (position < fileData.byteLength);\n",
       "  }\n",
       "\n",
       "  // All done.\n",
       "  yield {\n",
       "    response: {\n",
       "      action: 'complete',\n",
       "    }\n",
       "  };\n",
       "}\n",
       "\n",
       "scope.google = scope.google || {};\n",
       "scope.google.colab = scope.google.colab || {};\n",
       "scope.google.colab._files = {\n",
       "  _uploadFiles,\n",
       "  _uploadFilesContinue,\n",
       "};\n",
       "})(self);\n",
       "</script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving car_evaluation.csv to car_evaluation.csv\n"
     ]
    }
   ],
   "source": [
    "from google.colab import files # 데이터 불러오기\n",
    "file_uploaded=files.upload()   # 데이터 불러오기\n",
    "dataset = pd.read_csv('car_evaluation.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ea085b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 496,
     "status": "ok",
     "timestamp": 1715847857445,
     "user": {
      "displayName": "Bonghee Hong",
      "userId": "17805293653427923937"
     },
     "user_tz": -540
    },
    "id": "63ea085b",
    "outputId": "25949609-9d33-4b31-b5a0-e1f64c6a88f5"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"dataset\",\n  \"rows\": 1728,\n  \"fields\": [\n    {\n      \"column\": \"price\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"high\",\n          \"low\",\n          \"vhigh\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"maint\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"high\",\n          \"low\",\n          \"vhigh\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"doors\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"3\",\n          \"5more\",\n          \"2\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"persons\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"2\",\n          \"4\",\n          \"more\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"lug_capacity\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"small\",\n          \"med\",\n          \"big\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"safety\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"low\",\n          \"med\",\n          \"high\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"output\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"acc\",\n          \"good\",\n          \"unacc\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe",
       "variable_name": "dataset"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-ae4e8bd1-43cc-44f3-83d0-dcb687b78c31\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>maint</th>\n",
       "      <th>doors</th>\n",
       "      <th>persons</th>\n",
       "      <th>lug_capacity</th>\n",
       "      <th>safety</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>low</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>med</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>high</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>med</td>\n",
       "      <td>low</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>med</td>\n",
       "      <td>med</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ae4e8bd1-43cc-44f3-83d0-dcb687b78c31')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-ae4e8bd1-43cc-44f3-83d0-dcb687b78c31 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-ae4e8bd1-43cc-44f3-83d0-dcb687b78c31');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-cff4453a-1cf2-46e6-b353-61de473fb23d\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-cff4453a-1cf2-46e6-b353-61de473fb23d')\"\n",
       "            title=\"Suggest charts\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const quickchartButtonEl =\n",
       "        document.querySelector('#' + key + ' button');\n",
       "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "      try {\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      } catch (error) {\n",
       "        console.error('Error during call to suggestCharts:', error);\n",
       "      }\n",
       "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-cff4453a-1cf2-46e6-b353-61de473fb23d button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "   price  maint doors persons lug_capacity safety output\n",
       "0  vhigh  vhigh     2       2        small    low  unacc\n",
       "1  vhigh  vhigh     2       2        small    med  unacc\n",
       "2  vhigh  vhigh     2       2        small   high  unacc\n",
       "3  vhigh  vhigh     2       2          med    low  unacc\n",
       "4  vhigh  vhigh     2       2          med    med  unacc"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1854b091",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 517
    },
    "executionInfo": {
     "elapsed": 630,
     "status": "ok",
     "timestamp": 1715847866514,
     "user": {
      "displayName": "Bonghee Hong",
      "userId": "17805293653427923937"
     },
     "user_tz": -540
    },
    "id": "1854b091",
    "outputId": "35e2b6be-5ad5-4b18-a5df-c3c1e7cbd261"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: ylabel='count'>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig_size = plt.rcParams[\"figure.figsize\"]\n",
    "fig_size[0] = 8\n",
    "fig_size[1] = 6\n",
    "plt.rcParams[\"figure.figsize\"] = fig_size\n",
    "dataset.output.value_counts().plot(kind='pie', autopct='%0.05f%%', colors=['lightblue', 'lightgreen', 'orange', 'pink'], explode=(0.05, 0.05, 0.05,0.05))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c82b06",
   "metadata": {
    "id": "73c82b06"
   },
   "outputs": [],
   "source": [
    "categorical_columns = ['price', 'maint', 'doors', 'persons', 'lug_capacity', 'safety']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281fc4df",
   "metadata": {
    "id": "281fc4df"
   },
   "outputs": [],
   "source": [
    "for category in categorical_columns:\n",
    "    dataset[category] = dataset[category].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b735e5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 324,
     "status": "ok",
     "timestamp": 1715848096716,
     "user": {
      "displayName": "Bonghee Hong",
      "userId": "17805293653427923937"
     },
     "user_tz": -540
    },
    "id": "c6b735e5",
    "outputId": "f41449be-1574-466a-c17a-ee45dd5828d6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3, 3, 0, 0, 2, 1],\n",
       "       [3, 3, 0, 0, 2, 2],\n",
       "       [3, 3, 0, 0, 2, 0],\n",
       "       [3, 3, 0, 0, 1, 1],\n",
       "       [3, 3, 0, 0, 1, 2],\n",
       "       [3, 3, 0, 0, 1, 0],\n",
       "       [3, 3, 0, 0, 0, 1],\n",
       "       [3, 3, 0, 0, 0, 2],\n",
       "       [3, 3, 0, 0, 0, 0],\n",
       "       [3, 3, 0, 1, 2, 1]], dtype=int8)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "price = dataset['price'].cat.codes.values\n",
    "maint = dataset['maint'].cat.codes.values\n",
    "doors = dataset['doors'].cat.codes.values\n",
    "persons = dataset['persons'].cat.codes.values\n",
    "lug_capacity = dataset['lug_capacity'].cat.codes.values\n",
    "safety = dataset['safety'].cat.codes.values\n",
    "\n",
    "categorical_data = np.stack([price, maint, doors, persons, lug_capacity, safety], 1)\n",
    "categorical_data[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ea6d73",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 320,
     "status": "ok",
     "timestamp": 1715848214116,
     "user": {
      "displayName": "Bonghee Hong",
      "userId": "17805293653427923937"
     },
     "user_tz": -540
    },
    "id": "11ea6d73",
    "outputId": "c797995e-fdbf-421f-9930-8763c919ab0e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3, 3, 0, 0, 2, 1],\n",
       "        [3, 3, 0, 0, 2, 2],\n",
       "        [3, 3, 0, 0, 2, 0],\n",
       "        [3, 3, 0, 0, 1, 1],\n",
       "        [3, 3, 0, 0, 1, 2],\n",
       "        [3, 3, 0, 0, 1, 0],\n",
       "        [3, 3, 0, 0, 0, 1],\n",
       "        [3, 3, 0, 0, 0, 2],\n",
       "        [3, 3, 0, 0, 0, 0],\n",
       "        [3, 3, 0, 1, 2, 1]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_data = torch.tensor(categorical_data, dtype=torch.int64)\n",
    "categorical_data[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e765bcab",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 347,
     "status": "ok",
     "timestamp": 1715848236754,
     "user": {
      "displayName": "Bonghee Hong",
      "userId": "17805293653427923937"
     },
     "user_tz": -540
    },
    "id": "e765bcab",
    "outputId": "eec174b9-b68c-4edd-af44-43cf89394ad5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1728, 6])\n",
      "torch.Size([6912])\n"
     ]
    }
   ],
   "source": [
    "outputs = pd.get_dummies(dataset.output)\n",
    "outputs = outputs.values\n",
    "outputs = torch.tensor(outputs).flatten()\n",
    "\n",
    "print(categorical_data.shape)\n",
    "print(outputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "828e0711",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 353,
     "status": "ok",
     "timestamp": 1715779105896,
     "user": {
      "displayName": "Bonghee Hong",
      "userId": "17805293653427923937"
     },
     "user_tz": -540
    },
    "id": "828e0711",
    "outputId": "ae0b1728-a854-430a-ab0e-1d62a25d0032"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(4, 2), (4, 2), (4, 2), (3, 2), (3, 2), (3, 2)]\n"
     ]
    }
   ],
   "source": [
    "categorical_column_sizes = [len(dataset[column].cat.categories) for column in categorical_columns]\n",
    "categorical_embedding_sizes = [(col_size, min(50, (col_size+1)//2)) for col_size in categorical_column_sizes]\n",
    "print(categorical_embedding_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de38aa0b",
   "metadata": {
    "id": "de38aa0b"
   },
   "outputs": [],
   "source": [
    "total_records = 1728\n",
    "test_records = int(total_records * .2)\n",
    "\n",
    "categorical_train_data = categorical_data[:total_records-test_records]\n",
    "categorical_test_data = categorical_data[total_records-test_records:total_records]\n",
    "train_outputs = outputs[:total_records-test_records]\n",
    "test_outputs = outputs[total_records-test_records:total_records]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46eb162b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 298,
     "status": "ok",
     "timestamp": 1715779120682,
     "user": {
      "displayName": "Bonghee Hong",
      "userId": "17805293653427923937"
     },
     "user_tz": -540
    },
    "id": "46eb162b",
    "outputId": "6204c0ee-5140-46fe-99ce-b25e67c871de"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1383\n",
      "1383\n",
      "345\n",
      "345\n"
     ]
    }
   ],
   "source": [
    "print(len(categorical_train_data))\n",
    "print(len(train_outputs))\n",
    "print(len(categorical_test_data))\n",
    "print(len(test_outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eaa67ca",
   "metadata": {
    "id": "2eaa67ca"
   },
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, embedding_size, output_size, layers, p=0.4):\n",
    "        super().__init__()\n",
    "        self.all_embeddings = nn.ModuleList([nn.Embedding(ni, nf) for ni, nf in embedding_size])\n",
    "        self.embedding_dropout = nn.Dropout(p)\n",
    "\n",
    "        all_layers = []\n",
    "        num_categorical_cols = sum((nf for ni, nf in embedding_size))\n",
    "        input_size = num_categorical_cols\n",
    "\n",
    "        for i in layers:\n",
    "            all_layers.append(nn.Linear(input_size, i))\n",
    "            all_layers.append(nn.ReLU(inplace=True))\n",
    "            all_layers.append(nn.BatchNorm1d(i))\n",
    "            all_layers.append(nn.Dropout(p))\n",
    "            input_size = i\n",
    "\n",
    "        all_layers.append(nn.Linear(layers[-1], output_size))\n",
    "        self.layers = nn.Sequential(*all_layers)\n",
    "\n",
    "    def forward(self, x_categorical):\n",
    "        embeddings = []\n",
    "        for i,e in enumerate(self.all_embeddings):\n",
    "            embeddings.append(e(x_categorical[:,i]))\n",
    "        x = torch.cat(embeddings, 1)\n",
    "        x = self.embedding_dropout(x)\n",
    "        x = self.layers(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4909ff0e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 307,
     "status": "ok",
     "timestamp": 1715779161756,
     "user": {
      "displayName": "Bonghee Hong",
      "userId": "17805293653427923937"
     },
     "user_tz": -540
    },
    "id": "4909ff0e",
    "outputId": "7ae94821-419f-4147-b4b9-5d761bcb3320"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model(\n",
      "  (all_embeddings): ModuleList(\n",
      "    (0-2): 3 x Embedding(4, 2)\n",
      "    (3-5): 3 x Embedding(3, 2)\n",
      "  )\n",
      "  (embedding_dropout): Dropout(p=0.4, inplace=False)\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=12, out_features=200, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): Dropout(p=0.4, inplace=False)\n",
      "    (4): Linear(in_features=200, out_features=100, bias=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (7): Dropout(p=0.4, inplace=False)\n",
      "    (8): Linear(in_features=100, out_features=50, bias=True)\n",
      "    (9): ReLU(inplace=True)\n",
      "    (10): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (11): Dropout(p=0.4, inplace=False)\n",
      "    (12): Linear(in_features=50, out_features=4, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = Model(categorical_embedding_sizes, 4, [200,100,50], p=0.4)\n",
    "output_data = model(input_data)# forward() 메소드가 실행\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301d59a6",
   "metadata": {
    "id": "301d59a6"
   },
   "outputs": [],
   "source": [
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "KyuD2fLKM7Px",
   "metadata": {
    "id": "KyuD2fLKM7Px"
   },
   "outputs": [],
   "source": [
    "# 주어진 함수 정의\n",
    "def func(x):\n",
    "    return 5 * x ** 2 + 5 * x + 7\n",
    "\n",
    "# 도함수(미분) 계산\n",
    "def derivative(x):\n",
    "    return 10 * x + 5\n",
    "\n",
    "# 경사 하강법을 사용하여 기울기가 0인 지점 찾기\n",
    "def gradient_descent(learning_rate, initial_x, epochs):\n",
    "    x = initial_x\n",
    "    for _ in range(epochs):\n",
    "        gradient = derivative(x)\n",
    "        x = x - learning_rate * gradient\n",
    "    return x\n",
    "\n",
    "# 학습률, 초기값, 반복 횟수 설정\n",
    "learning_rate = 0.01\n",
    "initial_x = 0.0\n",
    "epochs = 1000\n",
    "\n",
    "# 경사 하강법 적용하여 기울기가 0인 지점 찾기\n",
    "optimal_x = gradient_descent(learning_rate, initial_x, epochs)\n",
    "optimal_y = func(optimal_x)\n",
    "\n",
    "# 결과 출력\n",
    "print(\"기울기가 0인 x:\", optimal_x)\n",
    "print(\"해당 지점에서의 y 값:\", optimal_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5c313f",
   "metadata": {
    "id": "3d5c313f"
   },
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56492e5b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "56492e5b",
    "outputId": "51e99adc-0975-422f-eb01-20719c4e3bcd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:   1 loss: 1.58690417\n",
      "epoch:  26 loss: 1.32208347\n",
      "epoch:  51 loss: 1.25037670\n",
      "epoch:  76 loss: 1.14533412\n",
      "epoch: 101 loss: 1.04376388\n",
      "epoch: 126 loss: 0.94333309\n",
      "epoch: 151 loss: 0.82459933\n",
      "epoch: 176 loss: 0.75102794\n",
      "epoch: 201 loss: 0.70688218\n",
      "epoch: 226 loss: 0.67204970\n",
      "epoch: 251 loss: 0.65042794\n",
      "epoch: 276 loss: 0.62593251\n",
      "epoch: 301 loss: 0.61263412\n",
      "epoch: 326 loss: 0.60477704\n",
      "epoch: 351 loss: 0.58988392\n",
      "epoch: 376 loss: 0.58695173\n",
      "epoch: 401 loss: 0.57759738\n",
      "epoch: 426 loss: 0.57076532\n",
      "epoch: 451 loss: 0.57889175\n",
      "epoch: 476 loss: 0.56059849\n",
      "epoch: 500 loss: 0.5716277361\n"
     ]
    }
   ],
   "source": [
    "epochs = 500\n",
    "aggregated_losses = []\n",
    "train_outputs = train_outputs.to(device=device, dtype=torch.int64)\n",
    "for i in range(epochs):\n",
    "    i += 1\n",
    "    y_pred = model(categorical_train_data).to(device)\n",
    "    single_loss = loss_function(y_pred, train_outputs)\n",
    "    aggregated_losses.append(single_loss)\n",
    "\n",
    "    if i%25 == 1:\n",
    "        print(f'epoch: {i:3} loss: {single_loss.item():10.8f}')\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    single_loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "print(f'epoch: {i:3} loss: {single_loss.item():10.10f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd2f1035",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fd2f1035",
    "outputId": "130d32d1-a203-4208-e327-eabb367e46fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.55816710\n"
     ]
    }
   ],
   "source": [
    "test_outputs = test_outputs.to(device=device, dtype=torch.int64)\n",
    "with torch.no_grad():\n",
    "    y_val = model(categorical_test_data).to(device)\n",
    "    loss = loss_function(y_val, test_outputs)\n",
    "print(f'Loss: {loss:.8f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6735f451",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6735f451",
    "outputId": "cdbe9174-23c8-43c2-e82d-e71f7607d11f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.5791,  0.8695, -2.0905, -1.9746],\n",
      "        [ 2.3801,  1.2895, -3.7661, -3.5672],\n",
      "        [ 2.7393,  1.5828, -3.9005, -3.7467],\n",
      "        [ 2.9840,  2.0176, -4.0020, -4.0287],\n",
      "        [ 2.7245,  1.8273, -3.2561, -3.0924]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(y_val[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5acf59f2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5acf59f2",
    "outputId": "f9a2ec26-2e2c-419c-d959-9c720b90bec4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "y_val = np.argmax(y_val.cpu().numpy(), axis=1)\n",
    "print(y_val[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e16502",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a7e16502",
    "outputId": "91fbee59-4b85-4bbc-9854-25da410bcd55"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[258   1]\n",
      " [ 86   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      1.00      0.86       259\n",
      "           1       0.00      0.00      0.00        86\n",
      "\n",
      "    accuracy                           0.75       345\n",
      "   macro avg       0.38      0.50      0.43       345\n",
      "weighted avg       0.56      0.75      0.64       345\n",
      "\n",
      "0.7478260869565218\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "test_outputs=test_outputs.cpu().numpy()\n",
    "print(confusion_matrix(test_outputs,y_val))\n",
    "print(classification_report(test_outputs,y_val))\n",
    "print(accuracy_score(test_outputs, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23a4969",
   "metadata": {
    "id": "c23a4969"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9HAW0ADKWTM4",
   "metadata": {
    "id": "9HAW0ADKWTM4"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "Vzrg4SeHdw65",
   "metadata": {
    "id": "Vzrg4SeHdw65"
   },
   "source": [
    "구글링: 2023.04.18 주피터노트북 VSCode 연동, 가상환경 만들기, GPU사용 환경 세팅(에러 해결 방법), 차유빈·2023년 4월 20일"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
